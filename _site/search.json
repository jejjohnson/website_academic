[
  {
    "objectID": "talks.html",
    "href": "talks.html",
    "title": "Talks",
    "section": "",
    "text": "2022\nImplicit Neural Representations for Sea Surface Height (a.k.a. Modern Optimal Interpolation)\nM2Lines Slides\nImplicit Neural Representations for Sea Surface Height (a.k.a. Modern Optimal Interpolation)\nSWOT Meetup\nSlides\n\n\n\n2021\nGaussianing the Earth: An Information Theoretic Perspective\nIGE Seminar\nSlides\nGaussianizing the Earth: An Information Theoretic Perspective\nMachine Learning in Science and Engineering\nSlides\nML4CC: Flood Extent Prediction\nTrillium\nSlides\nGLM Instrument Upgrade to Improve Extreme Weather Warnings\nEarth Science & AI Digital Showcase\nSlides | Video\n\n\n\n2020\nApplying GPs in the Wild\niMIRACLI Summer School\nSlides\nInput Uncertainty Propagation in Gaussian Process Regression Models\nKERMES 2020\nSlides\nKernel Alignment: The Empirical Analysis at the Parameter Space for RBF Kernels\nFast Friday Talks - ISP\nSlides\nHeliophysics Project Showcase: StarSpots\nSpace Science & AI Digital Showcase Presentation\nSlides | Video\n\n\n\n2019\nSensitivity Analysis for Gaussian Processes: Gradient-Based Methods for Emulation\nPhi-Week\nSlides | Code\nUnsupervised Machine Learning: Exploring Spatial Temporal Relationships and Drought Factors\nPhi-Week\nSlides | Code\nClimate Model Intercomparison with Multivariate Information Theoretic Measures\nAGU\nSlides\n\n\n\n2018\nKernel Methods for Earth Observation: Gaussian Processes and Derivatives\nSlides | Code\nInformation Theoretic Tools for the Earth Science Data Cubes\nEGU\nSlides"
  },
  {
    "objectID": "papers.html",
    "href": "papers.html",
    "title": "Papers",
    "section": "",
    "text": "For a more complete list, please see my google scholar page."
  },
  {
    "objectID": "papers.html#submitted",
    "href": "papers.html#submitted",
    "title": "Papers",
    "section": "Submitted",
    "text": "Submitted\nInformation theory measures via multidimensional Gaussianization\nValero Laparra, J. Emmanuel Johnson, Gustau Camps-Valls, Raul Santos-Rodríguez, Jesus Malo\nProject Web | Paper | Code"
  },
  {
    "objectID": "papers.html#published",
    "href": "papers.html#published",
    "title": "Papers",
    "section": "Published",
    "text": "Published\n\n2021\nGaussianizing the Earth: Multidimensional Information Measures for Earth Data Analysis\nJ Emmanuel Johnson, Valero Laparra, Maria Piles, Gustau Camps-Valls\nIEEE Geoscience and Remote Sensing Magazine\nPaper | Code\nLearning Relevant Features of Optical Water Types\nKatalin Blix, Ana Belen Ruescas, J. Emmanuel Johnson, Gustau Camps-Valls\nIEEE Geoscience and Remote Sensing Letters\nPaper\n\n\n2020\nKernel methods and their derivatives: Concept and perspectives for the earth system sciences\nJ. Emmanuel Johnson, Valero Laparra, Adrián Pérez-Suay, Miguel D Mahecha, Gustau Camps-Valls\nPLOS One\nPaper | Code\nEstimation of oceanic particulate organic carbon with machine learning\nRaphaëlle Sauzède, J. Emmanuel Johnson, Hervé Claustre, Gustau Camps-Valls, Ana Ruescas\nISPRS Annals of Photogrammetry, Remote Sensing and Spatial Information Sciences\nPaper (PDF) | Code\n\n\n2019\nAccounting for input noise in Gaussian process parameter retrieval\nJ. Emmanuel Johnson, Valero Laparra, Gustau Camps-Valls\nIEEE Geoscience and Remote Sensing Letters\nPaper | Code\n\n\n2016\nWind-driven circulation in a shallow microtidal estuary: The Indian River Lagoon\nRobert J Weaver, J. Emmanuel Johnson, Morgan Ridler\nJournal of Coastal Research\nPaper"
  },
  {
    "objectID": "conferences.html",
    "href": "conferences.html",
    "title": "J. Emmanuel Johnson",
    "section": "",
    "text": "Neural Fields: Modern Optimal Interpolation for Ocean Observation Data\nWorld Ocean Circulation User Consultation Meeting\nSlides (PDF)\nOrthonormal Convolutions for the Rotation Based Iterative Gaussianization\nValero Laparra, Alexander Hepburn, J. Emmanuel Johnson, Jesús Malo\nConference | Paper\nThe Kernelized Taylor Diagram\nKristoffer Wickstrøm, J. Emmanuel Johnson, Sigurd Løkse, Gustau Camps-Valls, Karl Øyvind Mikalsen, Michael Kampffmeyer, Robert Jenssen\n2022 Norweigian AI Society Symposium\nPaper | Code"
  },
  {
    "objectID": "conferences.html#section-1",
    "href": "conferences.html#section-1",
    "title": "J. Emmanuel Johnson",
    "section": "2022",
    "text": "2022\nNeural Fields for Fast and Scalable Interpolation of Geophysical Ocean Variables\nJ. Emmanuel Johnson, Redouane Lguensat, Ronan Fablet, Emmanuel Cosme, Julien Le Sommer\nNeurIPS, Machine Learning for Physical Sciences\nPaper"
  },
  {
    "objectID": "conferences.html#section-2",
    "href": "conferences.html#section-2",
    "title": "J. Emmanuel Johnson",
    "section": "2021",
    "text": "2021\nDetecting Spatiotemporal Lightning Patterns: An Unsupervised Graph-Based Approach\nEmma Benjaminson, Satyarth Praveen, Giulia Luise, J Emmanuel Johnson, Richard Strange, Milad Memarzadeh, Nadia Ahmed\nNeurIPS, Machine Learning for Physical Sciences\nPaper (PDF)"
  },
  {
    "objectID": "conferences.html#section-3",
    "href": "conferences.html#section-3",
    "title": "J. Emmanuel Johnson",
    "section": "2020",
    "text": "2020\nRotnet: Fast and scalable estimation of stellar rotation periods using convolutional neural networks\nJ. Emmanuel Johnson, Sairam Sundaresan, Tansu Daylan, Lisseth Gavilan, Daniel K Giles, Stela Ishitani Silva, Anna Jungbluth, Brett Morris, Andrés Muñoz-Jaramillo\nNeurIPS, Machine Learning for Physical Sciences\nPaper"
  },
  {
    "objectID": "conferences.html#section-4",
    "href": "conferences.html#section-4",
    "title": "J. Emmanuel Johnson",
    "section": "2019",
    "text": "2019\nInformation Theory in Density Destructors\nJ. Emmanuel Johnson, Valero Laparra, Raul Santos-Rodriguez, Gustau Camps-Valls, Jesus Malo\nICML, Invertible Neural Nets and Normalizing Flows\nPaper"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "J. Emmanuel Johnson",
    "section": "",
    "text": "These are the projects based on my academic research career, i.e. my Ph.D. and my current PostDoc.\n\n\nInvestingating how we can using machine learning in observation and computational oceanography. Specifically, we are working with geophysical observations obtained from satellite altimetry and we would like to constrain the solution with ocean models, e.g. NEMO, MITGCM. We approach this problem from a data assimilation formulation but with a machine learning perspective. Currently, we have broken this problem into 3 parts:\n\nUsing Neural Fields to interpolate sparse, noisy sea surface height data from altimetry satellites (nerf4ssh)\nUsing conditional generative models to learn surrogate models (cflow4surrgate)\nUsing neural networks to solve 4DVar problems (modern4dvar)\n\n\n\n\n\n\n\nNerF4SSH\n\n\n\n\n\nFor more information, see the following resources:\n\nGitHub Codebase\nResearch Notes\n\n\n\n\n\n\n\n\n\n\ncFlow4Surrogates (Coming Soon!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nModern4DVar (Coming Soon!)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n(a) SAKAME\n\n\n\n\n\n\n\n(b) EGP\n\n\n\n\nFigure 1: Summary figures of my work under the ERC project.\n\n\nIn this project, I looked at various ways we could use machine learning to characterize uncertainty in geoscience applications. ML is useful but it is often not understood. However, we demonstrate that there are two aspects that would help alleviate the idea that ML is a “black-box”: 1) error propagation and 2) sensitivity analysis.\n\n\n\n\n\n\nSAKAME\n\n\n\n\n\nTLDR: Investigating some connections between derivatives of kernel methods and standard sensitivity analysis in the physical sciences.\nWe looked at how there is a connection between the derivatives of kernel methods and standard sensitivity analysis seen in the physical sciences. We looked at\n\nJournal Article: Showcasing how derivatives of kernel methods are linked to\nGitHub Repo: all experiments are in here.\n\n\n\n\n\n\n\n\n\n\nEGP\n\n\n\n\n\nTLDR: Investigating how we can do error propagation through Gaussian process regression model.\nIn this project I looked at how we can propagate input uncertainty through GP regression models. GPs are the gold standard for having well calibrated predictive mean and variances. However, there is not much (recent) research on how we can propagate input uncertainty. So we looked at how this was possible in the context of geoscience.\n\nJournal Article: Showcasing how derivatives of kernel methods are linked to\nGitHub Repo: all experiments are in here.\nResearch Journal: A detailed walkthrough on the literature for input uncertainty in Gaussian processes.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Summary figures of my work under the USMILE project.\n\n\nIn this project, I looked at how we could use different machine learning methods to extract information from Earth System Data. We were given a massive amount of reanalysis data from various sources and we were interested to see how ML can be useful to extract information from said cubes. However, information theory is a difficult problem due to the curse of dimensionality which prohibits good density estimators that are necessary for said information theoretic metrics. We look at Gaussianization as a good density estimator with direct links to information theory due to the formulation.\n\n\n\n\n\n\nGauss4EO\n\n\n\n\n\nTLDR: We give a empirical deep-dive into showing how Gaussianization is a good information theoretic estimator.\nGaussianization is a long standing density estimation method. In fact it is the first ever “normalizing flow” method within the literature. We look at a particular version which is called the Rotation-Based Iterative Gaussianization method. We demonstrate its usefulness in including 1) time-memory for drought indicators, 2) redundancy in hyperspectral images, 3) sampling for hyperspectral images, and 4) entropy for different spatial-temporal configurations.\nMore resources for this project:\n\nJournal Article - Published work on formulation and applications to EO data.\nGitHub Repo - All codes for experiments with Gaussianization and Earth observation data.\nrbig - A numpy python package that implements the iterative Gaussianization method.\nrbig_jax - A JAX python package that implements the iterative and parametric Gaussianization method.\nAwesome-Normalizing-Flows - An indepth literature review of normalizing flows (and Gaussianization)\n\n\n\n\n\n\n\n\n\n\nGauss4IT\n\n\n\n\n\nTLDR: We showcase how Gaussianization is a good density estimator and information theoretic estimator for various in Geoscience applications.\nIn this project, we take a deep-dive into the Gaussianization formulation and demonstrate empirically how it can be used to estimate information theoretic quantities like entropy, mutual information, multivariate mutual information and the Kullback-Leibler Divergence.\n\nSubmitted Article - Work for the formulation and empirical evidence for its usefulness in different applications.\nProject Webpage - official webpage for the project and article\nGitHub Repo - All codes for experiments with Gaussianization and Earth observation data.\nrbig_matlab - A matlab package that implements the iterative Gaussianization method and corresponding IT methods.\nrbig_jax - A JAX python package that implements the iterative and parametric Gaussianization method."
  },
  {
    "objectID": "projects.html#fdl-sprint-glm-jun-2021---aug-2021",
    "href": "projects.html#fdl-sprint-glm-jun-2021---aug-2021",
    "title": "J. Emmanuel Johnson",
    "section": "FDL Sprint (GLM) | Jun 2021 - Aug 2021",
    "text": "FDL Sprint (GLM) | Jun 2021 - Aug 2021\n\n\n\nFigure 3: Summary figures of the FDL Sprint project [Slides].\n\n\nIn this project, we were concerned with extracting lightning events from the GLM Lightning mapper. I was a part of a team that built an end-to-end machine learning pipeline that was able help do filter the point clouds and extract features that were indicative of lightning. We tried the standard techniques like PCA, some deep learning techniques like AutoEncoders, and finally some new SOTA like Graphical Neural Networks.\n\nFor more resources see:\n\nProject Page\nSlides\nVideo\nGitHub Repo\nWorkshop Paper"
  },
  {
    "objectID": "projects.html#ml4cc-sprint-jan-2021---mar-2021",
    "href": "projects.html#ml4cc-sprint-jan-2021---mar-2021",
    "title": "J. Emmanuel Johnson",
    "section": "ML4CC Sprint | Jan 2021 - Mar 2021",
    "text": "ML4CC Sprint | Jan 2021 - Mar 2021\n\n\n\nFigure 4: Summary figures of the ML4CC project [Source].\n\n\nIn this project, we were concerned with predicting flood extent after a large storm via an onboard model on a satellite. I was a part of a team that built an end-to-end machine learning pipeline that was able help do just that. We implemented the following pipeline:\n\ndownloads multimodel remotely sensed multispectral images\npreprocesses heterogeneous data accordingly\naugments the images to increase sample size for training\ntrain a neural network model for image segmentation\ndownload a trained model to perform inference\nvisualize the image segmented image\n\nFor more resources see:\n\nProject Overview\nGitHub Repo - the repo with all the codes\nJupyterBook - A detailed tutorial document for the end-to-end pipeline.\nVideo"
  },
  {
    "objectID": "projects.html#fdl-sprint-starspots-jun-2020---aug-2020",
    "href": "projects.html#fdl-sprint-starspots-jun-2020---aug-2020",
    "title": "J. Emmanuel Johnson",
    "section": "FDL Sprint (StarSpots) | Jun 2020 - Aug 2020",
    "text": "FDL Sprint (StarSpots) | Jun 2020 - Aug 2020\n\n\n\nFigure 5: Summary figures of the FDL Spring project [Slides].\n\n\nIn this project, we were concerned with predicting spots on stars (as an indicator of star activity) from telescope data. I was a part of a team that built an end-to-end machine learning pipeline that was able help do just that. We were able to fit the data to get parameters using Bayesian inference. We were also able to use a neural network to predict star spot properties using transfer learning resulting in a x10K speed up!\n\nFor more resources see:\n\nProject Page\nSlides\nVideo\nWorkshop Paper"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "J. Emmanuel Johnson",
    "section": "",
    "text": "I am a CNRS post-Doctoral researcher at IGE/MEOM lab, where I am developing use cases for machine learning for computational and observation oceanography. My research has primarily applied machine learning in applications such as remote sensing, climate models, and observational oceanography. I usually work with large-scale spatial-temporal model simulations, reanalysis products or satellite observations with coordinate, grid-based or functional representations. I have an algorithmic background in manifold learning, kernel methods and information-theoretic measures. I specialize in (and typically apply) probabilistic models like Gaussian processes and generative models like Normalizing Flows, VAEs and Diffusion models.\nI see myself as a facilitator (a.k.a. Machine Learning Research Engineer): I like to create conceptual frameworks to consolidate research into easy-to-understand ideas, and I would like to build software tools to help others accomplish their goals. I also consider myself a Machine Learning Advocate: I like being the liaison between ML and the applied sciences. My future endeavours are to continuously improve upon my ML engineering skills and start to get a grasp on the MLOPs field, and advocate modern ML practices in the geoscience setting.\n\nThis website will host a list of my current and past projects, talks, conferences, and publications.\nFor more information regarding my projects, code tutorials and research notes, please go to my research journal.\n\n\n\n\n\n\nPh.D. in Electrical Engineering | Feb 2017 - June 2021\nUniversitat de Valéncia, València | Valencia, Spain\nThesis: Estimating Information in Earth System Data with Machine Learning\nM.S. in Applied and Computational Mathematics | Aug 2013 - Dec 2016\nRochester Institute of Technology | Rochester, NY, USA\nThesis: Schrödinger Eigenmaps for Manifold Alignment of Multimodal Hyperspectral Images\nB.S. in Oceanography, B.S. in Mathematical Sciences | Aug 2009 - May 2013\nFlorida Institute of Technology | Melbourne, FL, USA\n\n\n\n\n\n\n\n\nPostDoctoral Researcher | Sept 2021 - Now\nMEOM | IGE | CNRS | University of Grenoble-Alpes | Grenoble, France\nMachine Learning Researcher | Jun 2021 - Aug 2021\nTrillium Technologies | Remote\nMachine Learning Researcher | Jan 2021 - Mar 2021\nTrillium Technologies | Remote\nMachine Learning Researcher | Jun 2020 - Aug 2020\nTrillium Technologies | Remote\nImage Science Intern | Jun 2016 - Dec 2016\nUTC Aerospace Systems | Westford, Massachusetts, USA\nDesktop Support Field Technician | Sept 2011 - Apr 2013\nFlorida Institue of Technology | Melbourne, Florida, USA\nVideo Production Assistant | Oct 2009 - Jan 2011\nFlorida Institute of Technology | Melbourne, Florda, USA"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site"
  }
]